{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct Application of Ner with bert as explained in the blog\n",
    "- https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a\n",
    "- https://github.com/marcellusruben/medium-resources/blob/main/NER_BERT/NER_with_BERT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/copilot-model-run/code/Users/Soutrik.Chowdhury/abi_genai_bert_ner\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/copilot-model-run/code/Users/Soutrik.Chowdhury/abi_genai_bert_ner/\"\n",
    ")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM']=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertTokenizerFast, BertForTokenClassification\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-05\n",
    "EPOCHS = 7\n",
    "BATCH_SIZE = 8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "MAX_LEN=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = pd.read_csv(\"data/ner.csv\")\n",
    "ner_df_sample = ner_df.sample(frac=0.5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                           text  \\\n",
      "0                          Asia-Pacific Economic Cooperation leaders , meeting in Singapore , have called for more cooperation on global economic recovery efforts , and have warned against withdrawing economic stimulus measures too early .   \n",
      "1                                                                                                                                                             The United States has offered a $ 25-million reward for the capture of each man .   \n",
      "2                                                                                                                        Muhammad Arif was handed the death sentence Monday for his role in the December 2000 attack that killed three people .   \n",
      "3                                                                                                                         During 1992 - 93 , free presidential and National Assembly elections were held ending 17 years of single-party rule .   \n",
      "4  A poll published Friday in the Yediot Ahronot daily newspaper found that the Kadima party under acting Prime Minister Ehud Olmert would win 39 of 120 parliament seats , well ahead of the right-wing Likud party and moderate Labor party .   \n",
      "\n",
      "                                                                                                              labels  \n",
      "0                                      B-org I-org I-org O O O O B-org O O O O O O O O O O O O O O O O O O O O O O O  \n",
      "1                                                                            O B-gpe I-gpe O O O O O O O O O O O O O  \n",
      "2                                                      B-per I-per O O O O O B-tim O O O O O B-tim I-tim O O O O O O  \n",
      "3                                                    O B-tim I-tim I-tim O O O O B-org I-org O O O O B-tim O O O O O  \n",
      "4  O O O B-tim O O B-org I-org O O O O O B-geo O O O B-per I-per I-per I-per O O O O O O O O O O O O O O O O O O O O  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23980, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ner_df_sample.head())\n",
    "ner_df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, there are 9 entity categories with B/I varitaions, which are:\n",
    "\n",
    "* geo for geographical entity\n",
    "* org for organization entity\n",
    "* per for person entity\n",
    "* gpe for geopolitical entity\n",
    "* tim for time indicator entity\n",
    "* art for artifact entity\n",
    "* eve for event entity\n",
    "* nat for natural phenomenon entity\n",
    "* O is assigned if a word doesnâ€™t belong to any entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_data_preprocessing(df):\n",
    "    \"\"\"\n",
    "    This function will take the dataframe and return the text and labels list\n",
    "    \"\"\"\n",
    "    all_text_list = df[\"text\"].tolist()\n",
    "    if \"labels\" in df.columns.tolist():\n",
    "        all_labels_list = [i.split() for i in df[\"labels\"].tolist()]\n",
    "    else:\n",
    "        all_labels_list = None\n",
    "    return all_text_list, all_labels_list\n",
    "\n",
    "\n",
    "def create_label_mapping(all_labels_list):\n",
    "    \"\"\"\n",
    "    This function will take the labels list and return the label mapping\n",
    "    \"\"\"\n",
    "    unique_labels = set()\n",
    "    for lb in all_labels_list:\n",
    "        [unique_labels.add(i) for i in lb if i not in unique_labels]\n",
    "    # creating label mapping for keys\n",
    "    label_key_map = {v: k for k, v in enumerate(unique_labels)}\n",
    "    key_label_map = {k: v for k, v in enumerate(unique_labels)}\n",
    "\n",
    "    return label_key_map, key_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_list, all_labels_list = basic_data_preprocessing(ner_df_sample)\n",
    "label_key_map, key_label_map = create_label_mapping(all_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of all text list is: 23980\n",
      "The length of all labels list is: 23980\n",
      "The length of label key map is: 17\n",
      "The length of key label map is: 17\n",
      "The label key map is: {'I-org': 0, 'I-gpe': 1, 'B-art': 2, 'I-per': 3, 'B-gpe': 4, 'B-geo': 5, 'B-org': 6, 'I-geo': 7, 'B-eve': 8, 'I-eve': 9, 'O': 10, 'B-nat': 11, 'I-art': 12, 'I-nat': 13, 'B-tim': 14, 'I-tim': 15, 'B-per': 16}\n",
      "The key label map is: {0: 'I-org', 1: 'I-gpe', 2: 'B-art', 3: 'I-per', 4: 'B-gpe', 5: 'B-geo', 6: 'B-org', 7: 'I-geo', 8: 'B-eve', 9: 'I-eve', 10: 'O', 11: 'B-nat', 12: 'I-art', 13: 'I-nat', 14: 'B-tim', 15: 'I-tim', 16: 'B-per'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of all text list is: {len(all_text_list)}\")\n",
    "print(f\"The length of all labels list is: {len(all_labels_list)}\")\n",
    "print(f\"The length of label key map is: {len(label_key_map)}\")\n",
    "print(f\"The length of key label map is: {len(key_label_map)}\")\n",
    "print(f\"The label key map is: {label_key_map}\")\n",
    "print(f\"The key label map is: {key_label_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Alignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_label_example(tokenized_input, labels, label_key_map, label_all_tokens=True):\n",
    "    \"\"\"\n",
    "    Align the labels to the tokenized inputs. This can be used for NER or token classification tasks.\n",
    "    :param tokenized_input: Tokenized input from the tokenizer\n",
    "    :param labels: Labels to align\n",
    "    :param label_key_map: Mapping between the labels and the label ids\n",
    "    :param label_all_tokens: If True, all tokens are given a label. If False, only the first token of a word is given a label.\n",
    "\n",
    "    \"\"\"\n",
    "    # print(f\"label_key_map: {label_key_map}\")\n",
    "    word_ids = (\n",
    "        tokenized_input.word_ids()\n",
    "    )  # Return a list mapping the tokens to their actual word in the initial sentence\n",
    "    labels_ids = []  # list of labels for each token\n",
    "    previous_word_idx = None  # keep track of the previous word index\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            # print(f\"Word index is None: {word_idx}\")\n",
    "            labels_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            # print(\"current word index is not equal to previous word index\")\n",
    "            try:\n",
    "                labels_ids.append(label_key_map[labels[word_idx]])\n",
    "            except:\n",
    "                labels_ids.append(-100)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                labels_ids.append(\n",
    "                    label_key_map[labels[word_idx]] if label_all_tokens else -100\n",
    "                )\n",
    "            except:\n",
    "                labels_ids.append(-100)\n",
    "\n",
    "        # set the previous word index\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return labels_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last month , farmers , miners and labor groups held huge protests demanding nationalization of Bolivia 's oil industry and new elections .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# test the align label example function\n",
    "\n",
    "tokenizer_1 = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
    "sample_text = all_text_list[171]\n",
    "sample_labels = all_labels_list[171]\n",
    "print(sample_text)\n",
    "print(sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'offset_mapping', 'overflow_to_sample_mapping'])\n"
     ]
    }
   ],
   "source": [
    "op1 = tokenizer_1.encode_plus(\n",
    "    sample_text,\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=True,\n",
    "    return_attention_mask=True,\n",
    "    return_offsets_mapping=True,\n",
    "    return_special_tokens_mask=True,\n",
    "    return_overflowing_tokens=True,\n",
    "    \n",
    ")\n",
    "print(op1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Last', 'month', ',', 'farmers', ',', 'miners', 'and', 'labor', 'groups', 'held', 'huge', 'protests', 'demanding', 'national', '##ization', 'of', 'Bolivia', \"'\", 's', 'oil', 'industry', 'and', 'new', 'elections', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "27\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "sub_word_tokens = tokenizer_1.convert_ids_to_tokens(op1[\"input_ids\"][0])\n",
    "print(sub_word_tokens)\n",
    "print(len([id for id in sub_word_tokens if id != \"[PAD]\"]))\n",
    "print(len(sample_text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = align_label_example(\n",
    "    op1, sample_labels, label_key_map, label_all_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 10, 10, 10, 10, 10, 10, 10, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "['[CLS]', 'Last', 'month', ',', 'farmers', ',', 'miners', 'and', 'labor', 'groups', 'held', 'huge', 'protests', 'demanding', 'national', '##ization', 'of', 'Bolivia', \"'\", 's', 'oil', 'industry', 'and', 'new', 'elections', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(new_labels)\n",
    "print(sub_word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL']\n"
     ]
    }
   ],
   "source": [
    "print([key_label_map[i] if i != -100 else \"SPL\" for i in new_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        label_key_map,\n",
    "        label_all_tokens,\n",
    "        tokenizer,\n",
    "    ):\n",
    "        super(NerDataset, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.all_text_list, self.all_labels_list = basic_data_preprocessing(dataset)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.all_text_list = [\n",
    "            self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                max_length=MAX_LEN,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for text in self.all_text_list\n",
    "        ]\n",
    "\n",
    "        self.label_key_map = label_key_map\n",
    "        self.label_all_tokens = label_all_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.all_text_list[index]\n",
    "        labels = self.all_labels_list[index]\n",
    "\n",
    "        labels = align_label_example(\n",
    "            text, labels, self.label_key_map, self.label_all_tokens\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input\": text,\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerDatasetNew(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        label_key_map,\n",
    "        label_all_tokens,\n",
    "        tokenizer,\n",
    "    ):\n",
    "        super(NerDatasetNew, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.all_text_list, self.all_labels_list = basic_data_preprocessing(dataset)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_key_map = label_key_map\n",
    "        self.label_all_tokens = label_all_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.all_text_list[index]\n",
    "        labels = self.all_labels_list[index]\n",
    "\n",
    "        tokenized_input = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=MAX_LEN,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels = align_label_example(\n",
    "            tokenized_input, labels, self.label_key_map, self.label_all_tokens\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input\": tokenized_input,\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cfe29081064d6ca55a430661368726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0256305661e46d892bb2f7514b85199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6042182d4f4dfe9e71876c423f1b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae908e730e441bf8ab40cfa975fe663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\", force_download=True)\n",
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19184, 2) (4796, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(ner_df_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United Nations is praising the use of military helicopters to drop food and rescue survivors in tsunami-ravaged Indonesia , saying the aircraft are \" worth their weight in gold . \"\n"
     ]
    }
   ],
   "source": [
    "# final tetsing purposes\n",
    "real_df = ner_df.tail(1).reset_index(drop=True)\n",
    "test_text = real_df[\"text\"].tolist()[0]\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NerDataset(train_df, label_key_map, label_all_tokens, bert_tokenizer)\n",
    "test_dataset = NerDataset(test_df, label_key_map, label_all_tokens, bert_tokenizer)\n",
    "# real_dataset = NerDataset(real_df, label_key_map, label_all_tokens, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset_new = NerDatasetNew(train_df, label_key_map,\n",
    "#                                     label_all_tokens, bert_tokenizer)\n",
    "# test_dataset_new = NerDatasetNew(test_df, label_key_map,\n",
    "#                                     label_all_tokens, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers = 4\n",
    "\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers = 4\n",
    ")\n",
    "\n",
    "# real_dataloader = DataLoader(\n",
    "#     real_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     num_workers = 4\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2398 600\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader), len(test_dataloader)) # batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader_new = DataLoader(\n",
    "#     train_dataset_new,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=True,\n",
    "#     num_workers = 4\n",
    "# )\n",
    "# test_dataloader_new = DataLoader( \n",
    "#     test_dataset_new,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=False,\n",
    "#     num_workers = 4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 128])\n",
      "torch.Size([8, 128])\n",
      "tensor(-83347)\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "    print(data[\"input\"][\"input_ids\"].shape)\n",
    "    print(data[\"labels\"].shape)\n",
    "    print(data[\"labels\"].sum())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in test_dataloader_new:\n",
    "#     print(data[\"input\"][\"input_ids\"].shape)\n",
    "#     print(data[\"labels\"].shape)\n",
    "#     print(data[\"labels\"].sum())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both the dataset produce the same output , only diff is in the first way all text are pre tokenized before indexing for dataloader and in the second way the text is tokenized in the dataloader itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertNerModel(nn.Module):\n",
    "    def __init__(self, model_type: str, label_key_map: dict) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = BertForTokenClassification.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_type,\n",
    "            num_labels=len(label_key_map),\n",
    "            force_download=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            return_dict=False,\n",
    "        )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c300fb4ae8b540ab83bfc99d1674ffe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722c82f8ad7a4534b12280c5757df423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49152456ba9484089f6375d87e02c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertNerModel(\n",
       "  (bert): BertForTokenClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertNerModel(\"bert-base-cased\", label_key_map)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['bert.bert.embeddings.word_embeddings.weight', 'bert.bert.embeddings.position_embeddings.weight', 'bert.bert.embeddings.token_type_embeddings.weight', 'bert.bert.embeddings.LayerNorm.weight', 'bert.bert.embeddings.LayerNorm.bias', 'bert.bert.encoder.layer.0.attention.self.query.weight', 'bert.bert.encoder.layer.0.attention.self.query.bias', 'bert.bert.encoder.layer.0.attention.self.key.weight', 'bert.bert.encoder.layer.0.attention.self.key.bias', 'bert.bert.encoder.layer.0.attention.self.value.weight', 'bert.bert.encoder.layer.0.attention.self.value.bias', 'bert.bert.encoder.layer.0.attention.output.dense.weight', 'bert.bert.encoder.layer.0.attention.output.dense.bias', 'bert.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.0.intermediate.dense.weight', 'bert.bert.encoder.layer.0.intermediate.dense.bias', 'bert.bert.encoder.layer.0.output.dense.weight', 'bert.bert.encoder.layer.0.output.dense.bias', 'bert.bert.encoder.layer.0.output.LayerNorm.weight', 'bert.bert.encoder.layer.0.output.LayerNorm.bias', 'bert.bert.encoder.layer.1.attention.self.query.weight', 'bert.bert.encoder.layer.1.attention.self.query.bias', 'bert.bert.encoder.layer.1.attention.self.key.weight', 'bert.bert.encoder.layer.1.attention.self.key.bias', 'bert.bert.encoder.layer.1.attention.self.value.weight', 'bert.bert.encoder.layer.1.attention.self.value.bias', 'bert.bert.encoder.layer.1.attention.output.dense.weight', 'bert.bert.encoder.layer.1.attention.output.dense.bias', 'bert.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.1.intermediate.dense.weight', 'bert.bert.encoder.layer.1.intermediate.dense.bias', 'bert.bert.encoder.layer.1.output.dense.weight', 'bert.bert.encoder.layer.1.output.dense.bias', 'bert.bert.encoder.layer.1.output.LayerNorm.weight', 'bert.bert.encoder.layer.1.output.LayerNorm.bias', 'bert.bert.encoder.layer.2.attention.self.query.weight', 'bert.bert.encoder.layer.2.attention.self.query.bias', 'bert.bert.encoder.layer.2.attention.self.key.weight', 'bert.bert.encoder.layer.2.attention.self.key.bias', 'bert.bert.encoder.layer.2.attention.self.value.weight', 'bert.bert.encoder.layer.2.attention.self.value.bias', 'bert.bert.encoder.layer.2.attention.output.dense.weight', 'bert.bert.encoder.layer.2.attention.output.dense.bias', 'bert.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.2.intermediate.dense.weight', 'bert.bert.encoder.layer.2.intermediate.dense.bias', 'bert.bert.encoder.layer.2.output.dense.weight', 'bert.bert.encoder.layer.2.output.dense.bias', 'bert.bert.encoder.layer.2.output.LayerNorm.weight', 'bert.bert.encoder.layer.2.output.LayerNorm.bias', 'bert.bert.encoder.layer.3.attention.self.query.weight', 'bert.bert.encoder.layer.3.attention.self.query.bias', 'bert.bert.encoder.layer.3.attention.self.key.weight', 'bert.bert.encoder.layer.3.attention.self.key.bias', 'bert.bert.encoder.layer.3.attention.self.value.weight', 'bert.bert.encoder.layer.3.attention.self.value.bias', 'bert.bert.encoder.layer.3.attention.output.dense.weight', 'bert.bert.encoder.layer.3.attention.output.dense.bias', 'bert.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.3.intermediate.dense.weight', 'bert.bert.encoder.layer.3.intermediate.dense.bias', 'bert.bert.encoder.layer.3.output.dense.weight', 'bert.bert.encoder.layer.3.output.dense.bias', 'bert.bert.encoder.layer.3.output.LayerNorm.weight', 'bert.bert.encoder.layer.3.output.LayerNorm.bias', 'bert.bert.encoder.layer.4.attention.self.query.weight', 'bert.bert.encoder.layer.4.attention.self.query.bias', 'bert.bert.encoder.layer.4.attention.self.key.weight', 'bert.bert.encoder.layer.4.attention.self.key.bias', 'bert.bert.encoder.layer.4.attention.self.value.weight', 'bert.bert.encoder.layer.4.attention.self.value.bias', 'bert.bert.encoder.layer.4.attention.output.dense.weight', 'bert.bert.encoder.layer.4.attention.output.dense.bias', 'bert.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.4.intermediate.dense.weight', 'bert.bert.encoder.layer.4.intermediate.dense.bias', 'bert.bert.encoder.layer.4.output.dense.weight', 'bert.bert.encoder.layer.4.output.dense.bias', 'bert.bert.encoder.layer.4.output.LayerNorm.weight', 'bert.bert.encoder.layer.4.output.LayerNorm.bias', 'bert.bert.encoder.layer.5.attention.self.query.weight', 'bert.bert.encoder.layer.5.attention.self.query.bias', 'bert.bert.encoder.layer.5.attention.self.key.weight', 'bert.bert.encoder.layer.5.attention.self.key.bias', 'bert.bert.encoder.layer.5.attention.self.value.weight', 'bert.bert.encoder.layer.5.attention.self.value.bias', 'bert.bert.encoder.layer.5.attention.output.dense.weight', 'bert.bert.encoder.layer.5.attention.output.dense.bias', 'bert.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.5.intermediate.dense.weight', 'bert.bert.encoder.layer.5.intermediate.dense.bias', 'bert.bert.encoder.layer.5.output.dense.weight', 'bert.bert.encoder.layer.5.output.dense.bias', 'bert.bert.encoder.layer.5.output.LayerNorm.weight', 'bert.bert.encoder.layer.5.output.LayerNorm.bias', 'bert.bert.encoder.layer.6.attention.self.query.weight', 'bert.bert.encoder.layer.6.attention.self.query.bias', 'bert.bert.encoder.layer.6.attention.self.key.weight', 'bert.bert.encoder.layer.6.attention.self.key.bias', 'bert.bert.encoder.layer.6.attention.self.value.weight', 'bert.bert.encoder.layer.6.attention.self.value.bias', 'bert.bert.encoder.layer.6.attention.output.dense.weight', 'bert.bert.encoder.layer.6.attention.output.dense.bias', 'bert.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.6.intermediate.dense.weight', 'bert.bert.encoder.layer.6.intermediate.dense.bias', 'bert.bert.encoder.layer.6.output.dense.weight', 'bert.bert.encoder.layer.6.output.dense.bias', 'bert.bert.encoder.layer.6.output.LayerNorm.weight', 'bert.bert.encoder.layer.6.output.LayerNorm.bias', 'bert.bert.encoder.layer.7.attention.self.query.weight', 'bert.bert.encoder.layer.7.attention.self.query.bias', 'bert.bert.encoder.layer.7.attention.self.key.weight', 'bert.bert.encoder.layer.7.attention.self.key.bias', 'bert.bert.encoder.layer.7.attention.self.value.weight', 'bert.bert.encoder.layer.7.attention.self.value.bias', 'bert.bert.encoder.layer.7.attention.output.dense.weight', 'bert.bert.encoder.layer.7.attention.output.dense.bias', 'bert.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.7.intermediate.dense.weight', 'bert.bert.encoder.layer.7.intermediate.dense.bias', 'bert.bert.encoder.layer.7.output.dense.weight', 'bert.bert.encoder.layer.7.output.dense.bias', 'bert.bert.encoder.layer.7.output.LayerNorm.weight', 'bert.bert.encoder.layer.7.output.LayerNorm.bias', 'bert.bert.encoder.layer.8.attention.self.query.weight', 'bert.bert.encoder.layer.8.attention.self.query.bias', 'bert.bert.encoder.layer.8.attention.self.key.weight', 'bert.bert.encoder.layer.8.attention.self.key.bias', 'bert.bert.encoder.layer.8.attention.self.value.weight', 'bert.bert.encoder.layer.8.attention.self.value.bias', 'bert.bert.encoder.layer.8.attention.output.dense.weight', 'bert.bert.encoder.layer.8.attention.output.dense.bias', 'bert.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.8.intermediate.dense.weight', 'bert.bert.encoder.layer.8.intermediate.dense.bias', 'bert.bert.encoder.layer.8.output.dense.weight', 'bert.bert.encoder.layer.8.output.dense.bias', 'bert.bert.encoder.layer.8.output.LayerNorm.weight', 'bert.bert.encoder.layer.8.output.LayerNorm.bias', 'bert.bert.encoder.layer.9.attention.self.query.weight', 'bert.bert.encoder.layer.9.attention.self.query.bias', 'bert.bert.encoder.layer.9.attention.self.key.weight', 'bert.bert.encoder.layer.9.attention.self.key.bias', 'bert.bert.encoder.layer.9.attention.self.value.weight', 'bert.bert.encoder.layer.9.attention.self.value.bias', 'bert.bert.encoder.layer.9.attention.output.dense.weight', 'bert.bert.encoder.layer.9.attention.output.dense.bias', 'bert.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.9.intermediate.dense.weight', 'bert.bert.encoder.layer.9.intermediate.dense.bias', 'bert.bert.encoder.layer.9.output.dense.weight', 'bert.bert.encoder.layer.9.output.dense.bias', 'bert.bert.encoder.layer.9.output.LayerNorm.weight', 'bert.bert.encoder.layer.9.output.LayerNorm.bias', 'bert.bert.encoder.layer.10.attention.self.query.weight', 'bert.bert.encoder.layer.10.attention.self.query.bias', 'bert.bert.encoder.layer.10.attention.self.key.weight', 'bert.bert.encoder.layer.10.attention.self.key.bias', 'bert.bert.encoder.layer.10.attention.self.value.weight', 'bert.bert.encoder.layer.10.attention.self.value.bias', 'bert.bert.encoder.layer.10.attention.output.dense.weight', 'bert.bert.encoder.layer.10.attention.output.dense.bias', 'bert.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.10.intermediate.dense.weight', 'bert.bert.encoder.layer.10.intermediate.dense.bias', 'bert.bert.encoder.layer.10.output.dense.weight', 'bert.bert.encoder.layer.10.output.dense.bias', 'bert.bert.encoder.layer.10.output.LayerNorm.weight', 'bert.bert.encoder.layer.10.output.LayerNorm.bias', 'bert.bert.encoder.layer.11.attention.self.query.weight', 'bert.bert.encoder.layer.11.attention.self.query.bias', 'bert.bert.encoder.layer.11.attention.self.key.weight', 'bert.bert.encoder.layer.11.attention.self.key.bias', 'bert.bert.encoder.layer.11.attention.self.value.weight', 'bert.bert.encoder.layer.11.attention.self.value.bias', 'bert.bert.encoder.layer.11.attention.output.dense.weight', 'bert.bert.encoder.layer.11.attention.output.dense.bias', 'bert.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.bert.encoder.layer.11.intermediate.dense.weight', 'bert.bert.encoder.layer.11.intermediate.dense.bias', 'bert.bert.encoder.layer.11.output.dense.weight', 'bert.bert.encoder.layer.11.output.dense.bias', 'bert.bert.encoder.layer.11.output.LayerNorm.weight', 'bert.bert.encoder.layer.11.output.LayerNorm.bias', 'bert.classifier.weight', 'bert.classifier.bias'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-308353.8750, device='cuda:0')\n",
      "tensor(1.7204, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().get(\"bert.bert.embeddings.word_embeddings.weight\").sum())\n",
    "print(model.state_dict().get(\"bert.bert.embeddings.position_embeddings.weight\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = data[\"input\"][\"input_ids\"].to(device)\n",
    "# attention_mask = data[\"input\"][\"attention_mask\"].to(device)\n",
    "# labels = data[\"labels\"].to(device)\n",
    "\n",
    "# print(input_ids.shape, attention_mask.shape, labels.shape)\n",
    "# input_ids = input_ids.squeeze(1)\n",
    "# attention_mask = attention_mask.squeeze(1)\n",
    "# print(input_ids.shape, attention_mask.shape)\n",
    "# model.train()\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# outputs = model(input_ids, attention_mask, labels=labels)\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pre training setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing to apply decay based on the layer type excluding bias and LayerNorm weights and include transformer layers\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16786\n"
     ]
    }
   ],
   "source": [
    "# total no of training steps : len(dataset)/batch_size * epochs = len(train_dataloader) * epochs\n",
    "\n",
    "num_training_steps = len(train_dataloader) * EPOCHS\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/torch_env/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(optimizer_parameters, lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=100, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(\n",
    "    epoch, model, optimizer, scheduler, dataloader, device, label_key_map\n",
    "):\n",
    "    \"\"\"Function to run the training loop for each epoch\"\"\"\n",
    "    tr_loss, tr_accuracy = 0.0, 0.0\n",
    "    tr_examples, tr_steps = 0, 0\n",
    "    tr_preds = []\n",
    "    tr_labels = []\n",
    "\n",
    "    # put the model in training mode:\n",
    "    model.train()\n",
    "\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        input_ids = batch[\"input\"][\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"input\"][\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # squeeze the input_ids and attention_mask\n",
    "        input_ids = input_ids.squeeze(1)\n",
    "        attention_mask = attention_mask.squeeze(1)\n",
    "\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        loss, logits = model(input_ids, attention_mask, labels=labels)\n",
    "\n",
    "        # loss = output.loss\n",
    "        # logits = output.logits\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        tr_steps += 1  # steps are the number of batches in each epoch\n",
    "        tr_examples += labels.size(0)\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            loss_step = tr_loss / tr_examples\n",
    "            print(f\"For Epoch: {epoch}, Step: {idx}, Train Loss: {loss_step}\")\n",
    "\n",
    "        # flatten targets and predictions\n",
    "        flattened_targets = labels.view(\n",
    "            -1\n",
    "        )  # from (batch_size, seq_len) to (batch_size*seq_len,)\n",
    "        active_logits = logits.view(\n",
    "            -1, len(label_key_map)\n",
    "        )  # from (batch_size, seq_len, num_labels) to (batch_size*seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(\n",
    "            active_logits, axis=1\n",
    "        )  # from (batch_size*seq_len, num_labels) to (batch_size*seq_len,)\n",
    "\n",
    "        # only consider labels and predictions to store and calc metric on valid ones\n",
    "        active_accuracy = labels.view(-1) != -100  # shape (batch_size, seq_len)\n",
    "        labels = torch.masked_select(\n",
    "            flattened_targets, active_accuracy\n",
    "        )  # shape (valid_labels,)\n",
    "        predictions = torch.masked_select(\n",
    "            flattened_predictions, active_accuracy\n",
    "        )  # shape (valid_labels,)\n",
    "\n",
    "        # store predictions and labels\n",
    "        tr_preds.extend(predictions.cpu().numpy())\n",
    "        tr_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # calc acc score\n",
    "        tmp_tr_accuracy = accuracy_score(\n",
    "            labels.cpu().numpy(), predictions.cpu().numpy()\n",
    "        )\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    epoch_loss = tr_loss / tr_examples\n",
    "    epoch_accuracy = tr_accuracy / tr_steps\n",
    "    print(\n",
    "        f\"For Epoch: {epoch}, Train Loss: {epoch_loss}, Train Accuracy: {epoch_accuracy}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(epoch, model, dataloader, device, label_key_map, key_label_map):\n",
    "    val_loss, val_accuracy = 0.0, 0.0\n",
    "    val_examples, val_steps = 0, 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    # put the model in evaluation mode:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            input_ids = batch[\"input\"][\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"input\"][\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # squeeze the input_ids and attention_mask\n",
    "            input_ids = input_ids.squeeze(1)\n",
    "            attention_mask = attention_mask.squeeze(1)\n",
    "\n",
    "            loss, logits = model(input_ids, attention_mask, labels=labels)\n",
    "\n",
    "            # loss = outputs.loss\n",
    "            # logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_steps += 1\n",
    "            val_examples += labels.size(0)\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                loss_step = val_loss / val_examples\n",
    "                print(f\"For Epoch: {epoch}, Step: {idx}, Val Loss: {loss_step}\")\n",
    "\n",
    "            # flatten targets and predictions\n",
    "            flattened_targets = labels.view(\n",
    "                -1\n",
    "            )  # from (batch_size, seq_len) to (batch_size*seq_len,)\n",
    "            active_logits = logits.view(\n",
    "                -1, len(label_key_map)\n",
    "            )  # from (batch_size, seq_len, num_labels) to (batch_size*seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(\n",
    "                active_logits, axis=1\n",
    "            )  # from (batch_size*seq_len, num_labels) to (batch_size*seq_len,)\n",
    "\n",
    "            # only consider labels and predictions to store and calc metric on valid ones\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "            labels = torch.masked_select(\n",
    "                flattened_targets, active_accuracy\n",
    "            )  # shape (valid_labels,)\n",
    "            predictions = torch.masked_select(\n",
    "                flattened_predictions, active_accuracy\n",
    "            )  # shape (valid_labels,)\n",
    "\n",
    "            # store predictions and labels\n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            tmp_val_accuracy = accuracy_score(\n",
    "                labels.cpu().numpy(), predictions.cpu().numpy()\n",
    "            )\n",
    "            val_accuracy += tmp_val_accuracy\n",
    "\n",
    "    # we change the predicted labels to actual labels\n",
    "    val_labels = [key_label_map[id] for id in val_labels]\n",
    "    val_preds = [key_label_map[id] for id in val_preds]\n",
    "\n",
    "    epoch_loss = val_loss / val_examples\n",
    "    epoch_accuracy = val_accuracy / val_steps\n",
    "\n",
    "    print(f\"For Epoch: {epoch}, Val Loss: {epoch_loss}, Val Accuracy: {epoch_accuracy}\")\n",
    "\n",
    "    return val_labels, val_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gpu_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Loop\n",
      "For Epoch: 0, Step: 0, Train Loss: 0.3688517212867737\n",
      "For Epoch: 0, Step: 100, Train Loss: 0.15192103275273106\n",
      "For Epoch: 0, Step: 200, Train Loss: 0.13046029964415587\n",
      "For Epoch: 0, Step: 300, Train Loss: 0.12165459928619506\n",
      "For Epoch: 0, Step: 400, Train Loss: 0.11800032593031179\n",
      "For Epoch: 0, Step: 500, Train Loss: 0.11537483553894741\n",
      "For Epoch: 0, Step: 600, Train Loss: 0.11324406981145879\n",
      "For Epoch: 0, Step: 700, Train Loss: 0.11240440684658995\n",
      "For Epoch: 0, Step: 800, Train Loss: 0.11211973428726196\n",
      "For Epoch: 0, Step: 900, Train Loss: 0.11140384230675893\n",
      "For Epoch: 0, Step: 1000, Train Loss: 0.1104374039549749\n",
      "For Epoch: 0, Step: 1100, Train Loss: 0.10990672386661646\n",
      "For Epoch: 0, Step: 1200, Train Loss: 0.10976820738736438\n",
      "For Epoch: 0, Step: 1300, Train Loss: 0.10950165763669156\n",
      "For Epoch: 0, Step: 1400, Train Loss: 0.1094331565332319\n",
      "For Epoch: 0, Step: 1500, Train Loss: 0.10912767358665304\n",
      "For Epoch: 0, Step: 1600, Train Loss: 0.10902707379713869\n",
      "For Epoch: 0, Step: 1700, Train Loss: 0.10871263735132103\n",
      "For Epoch: 0, Step: 1800, Train Loss: 0.10865835296295207\n",
      "For Epoch: 0, Step: 1900, Train Loss: 0.10832552819942437\n",
      "For Epoch: 0, Step: 2000, Train Loss: 0.1081319238836023\n",
      "For Epoch: 0, Step: 2100, Train Loss: 0.10811971471437042\n",
      "For Epoch: 0, Step: 2200, Train Loss: 0.1080056777454977\n",
      "For Epoch: 0, Step: 2300, Train Loss: 0.10774641300428955\n",
      "For Epoch: 0, Train Loss: 0.10764502164899209, Train Accuracy: 0.8257659433279582\n",
      "Validation Loop\n",
      "For Epoch: 0, Step: 0, Val Loss: 0.09885410964488983\n",
      "For Epoch: 0, Step: 100, Val Loss: 0.09890917614840045\n",
      "For Epoch: 0, Step: 200, Val Loss: 0.10102994063526244\n",
      "For Epoch: 0, Step: 300, Val Loss: 0.10169764426211979\n",
      "For Epoch: 0, Step: 400, Val Loss: 0.10308107916739516\n",
      "For Epoch: 0, Step: 500, Val Loss: 0.10374320734909433\n",
      "For Epoch: 0, Val Loss: 0.1044159214182433, Val Accuracy: 0.8271120878158308\n",
      "Epoch: 1\n",
      "Training Loop\n",
      "For Epoch: 1, Step: 0, Train Loss: 0.09879790246486664\n",
      "For Epoch: 1, Step: 100, Train Loss: 0.10904544968121123\n",
      "For Epoch: 1, Step: 200, Train Loss: 0.10798643579456343\n",
      "For Epoch: 1, Step: 300, Train Loss: 0.10640224285943564\n",
      "For Epoch: 1, Step: 400, Train Loss: 0.10623444650238589\n",
      "For Epoch: 1, Step: 500, Train Loss: 0.10586799841797995\n",
      "For Epoch: 1, Step: 600, Train Loss: 0.10564610917437295\n",
      "For Epoch: 1, Step: 700, Train Loss: 0.10528623192078207\n",
      "For Epoch: 1, Step: 800, Train Loss: 0.10560197661283162\n",
      "For Epoch: 1, Step: 900, Train Loss: 0.10566790751724212\n",
      "For Epoch: 1, Step: 1000, Train Loss: 0.10532846762152104\n",
      "For Epoch: 1, Step: 1100, Train Loss: 0.10508005726036973\n",
      "For Epoch: 1, Step: 1200, Train Loss: 0.10475921846436125\n",
      "For Epoch: 1, Step: 1300, Train Loss: 0.10469934572218749\n",
      "For Epoch: 1, Step: 1400, Train Loss: 0.10481014855998401\n",
      "For Epoch: 1, Step: 1500, Train Loss: 0.10468372509508908\n",
      "For Epoch: 1, Step: 1600, Train Loss: 0.1045733887509098\n",
      "For Epoch: 1, Step: 1700, Train Loss: 0.10448147350597004\n",
      "For Epoch: 1, Step: 1800, Train Loss: 0.10447577310975295\n",
      "For Epoch: 1, Step: 1900, Train Loss: 0.10458774493320373\n",
      "For Epoch: 1, Step: 2000, Train Loss: 0.10462555116687579\n",
      "For Epoch: 1, Step: 2100, Train Loss: 0.10453512520484559\n",
      "For Epoch: 1, Step: 2200, Train Loss: 0.10453840292167631\n",
      "For Epoch: 1, Step: 2300, Train Loss: 0.10463017302815006\n",
      "For Epoch: 1, Train Loss: 0.10459557002576517, Train Accuracy: 0.827472241785594\n",
      "Validation Loop\n",
      "For Epoch: 1, Step: 0, Val Loss: 0.0981021523475647\n",
      "For Epoch: 1, Step: 100, Val Loss: 0.098992571787964\n",
      "For Epoch: 1, Step: 200, Val Loss: 0.10100158528234829\n",
      "For Epoch: 1, Step: 300, Val Loss: 0.10175127335561074\n",
      "For Epoch: 1, Step: 400, Val Loss: 0.10316512349091861\n",
      "For Epoch: 1, Step: 500, Val Loss: 0.10377545372216763\n",
      "For Epoch: 1, Val Loss: 0.10439576806377827, Val Accuracy: 0.8271120878158308\n",
      "Epoch: 2\n",
      "Training Loop\n",
      "For Epoch: 2, Step: 0, Train Loss: 0.13728098571300507\n",
      "For Epoch: 2, Step: 100, Train Loss: 0.1026642272746799\n",
      "For Epoch: 2, Step: 200, Train Loss: 0.10564353007508155\n",
      "For Epoch: 2, Step: 300, Train Loss: 0.10496672667389692\n",
      "For Epoch: 2, Step: 400, Train Loss: 0.10420613708044228\n",
      "For Epoch: 2, Step: 500, Train Loss: 0.10406508168833936\n",
      "For Epoch: 2, Step: 600, Train Loss: 0.10463599320160172\n",
      "For Epoch: 2, Step: 700, Train Loss: 0.10436446436504154\n",
      "For Epoch: 2, Step: 800, Train Loss: 0.10411260947213041\n",
      "For Epoch: 2, Step: 900, Train Loss: 0.10423014901338619\n",
      "For Epoch: 2, Step: 1000, Train Loss: 0.10428621512758625\n",
      "For Epoch: 2, Step: 1100, Train Loss: 0.10414191281979567\n",
      "For Epoch: 2, Step: 1200, Train Loss: 0.1043566426077701\n",
      "For Epoch: 2, Step: 1300, Train Loss: 0.10418828238635042\n",
      "For Epoch: 2, Step: 1400, Train Loss: 0.10435318102332884\n",
      "For Epoch: 2, Step: 1500, Train Loss: 0.10414854825774007\n",
      "For Epoch: 2, Step: 1600, Train Loss: 0.10426789611754829\n",
      "For Epoch: 2, Step: 1700, Train Loss: 0.10438969245137782\n",
      "For Epoch: 2, Step: 1800, Train Loss: 0.10413699321808714\n",
      "For Epoch: 2, Step: 1900, Train Loss: 0.10412340594562401\n",
      "For Epoch: 2, Step: 2000, Train Loss: 0.1041785817144663\n",
      "For Epoch: 2, Step: 2100, Train Loss: 0.10422349855417243\n",
      "For Epoch: 2, Step: 2200, Train Loss: 0.10420643513694723\n",
      "For Epoch: 2, Step: 2300, Train Loss: 0.10411268123941596\n",
      "For Epoch: 2, Train Loss: 0.10411407168895578, Train Accuracy: 0.8274518104999298\n",
      "Validation Loop\n",
      "For Epoch: 2, Step: 0, Val Loss: 0.09792078286409378\n",
      "For Epoch: 2, Step: 100, Val Loss: 0.09864507379508254\n",
      "For Epoch: 2, Step: 200, Val Loss: 0.1006861853955397\n",
      "For Epoch: 2, Step: 300, Val Loss: 0.10138266318264198\n",
      "For Epoch: 2, Step: 400, Val Loss: 0.10277257562426854\n",
      "For Epoch: 2, Step: 500, Val Loss: 0.10339383657523496\n",
      "For Epoch: 2, Val Loss: 0.10404235350156049, Val Accuracy: 0.8271120878158308\n",
      "Epoch: 3\n",
      "Training Loop\n",
      "For Epoch: 3, Step: 0, Train Loss: 0.0821809321641922\n",
      "For Epoch: 3, Step: 100, Train Loss: 0.10652731023360007\n",
      "For Epoch: 3, Step: 200, Train Loss: 0.10432700290163952\n",
      "For Epoch: 3, Step: 300, Train Loss: 0.10387401456056639\n",
      "For Epoch: 3, Step: 400, Train Loss: 0.10359428555442211\n",
      "For Epoch: 3, Step: 500, Train Loss: 0.1032508195948577\n",
      "For Epoch: 3, Step: 600, Train Loss: 0.10345280772933547\n",
      "For Epoch: 3, Step: 700, Train Loss: 0.10324726339838815\n",
      "For Epoch: 3, Step: 800, Train Loss: 0.10365330592523353\n",
      "For Epoch: 3, Step: 900, Train Loss: 0.10352586799783924\n",
      "For Epoch: 3, Step: 1000, Train Loss: 0.10369551402854395\n",
      "For Epoch: 3, Step: 1100, Train Loss: 0.10367035959846425\n",
      "For Epoch: 3, Step: 1200, Train Loss: 0.10363652678415936\n",
      "For Epoch: 3, Step: 1300, Train Loss: 0.10378372838447224\n",
      "For Epoch: 3, Step: 1400, Train Loss: 0.10389118724842313\n",
      "For Epoch: 3, Step: 1500, Train Loss: 0.10386650479689667\n",
      "For Epoch: 3, Step: 1600, Train Loss: 0.10398274476289153\n",
      "For Epoch: 3, Step: 1700, Train Loss: 0.10394740598752596\n",
      "For Epoch: 3, Step: 1800, Train Loss: 0.1038876552318845\n",
      "For Epoch: 3, Step: 1900, Train Loss: 0.10375384346771592\n",
      "For Epoch: 3, Step: 2000, Train Loss: 0.10369618650319158\n",
      "For Epoch: 3, Step: 2100, Train Loss: 0.10389023602916649\n",
      "For Epoch: 3, Step: 2200, Train Loss: 0.1037708817727725\n",
      "For Epoch: 3, Step: 2300, Train Loss: 0.10388376845653188\n",
      "For Epoch: 3, Train Loss: 0.1040146855017585, Train Accuracy: 0.827338530709593\n",
      "Validation Loop\n",
      "For Epoch: 3, Step: 0, Val Loss: 0.09997880458831787\n",
      "For Epoch: 3, Step: 100, Val Loss: 0.09920650130451315\n",
      "For Epoch: 3, Step: 200, Val Loss: 0.10111623839359378\n",
      "For Epoch: 3, Step: 300, Val Loss: 0.10178048277515113\n",
      "For Epoch: 3, Step: 400, Val Loss: 0.10307722313891622\n",
      "For Epoch: 3, Step: 500, Val Loss: 0.10366505487057977\n",
      "For Epoch: 3, Val Loss: 0.10429254135705711, Val Accuracy: 0.8271120878158308\n",
      "Epoch: 4\n",
      "Training Loop\n",
      "For Epoch: 4, Step: 0, Train Loss: 0.13052485883235931\n",
      "For Epoch: 4, Step: 100, Train Loss: 0.10341863525976049\n",
      "For Epoch: 4, Step: 200, Train Loss: 0.10193650617231777\n",
      "For Epoch: 4, Step: 300, Train Loss: 0.10329892506136054\n",
      "For Epoch: 4, Step: 400, Train Loss: 0.10329388600409477\n",
      "For Epoch: 4, Step: 500, Train Loss: 0.10300829721811765\n",
      "For Epoch: 4, Step: 600, Train Loss: 0.10362936481337578\n",
      "For Epoch: 4, Step: 700, Train Loss: 0.10350470574368084\n",
      "For Epoch: 4, Step: 800, Train Loss: 0.10335652960857351\n",
      "For Epoch: 4, Step: 900, Train Loss: 0.10373364901635279\n",
      "For Epoch: 4, Step: 1000, Train Loss: 0.10387311446723285\n",
      "For Epoch: 4, Step: 1100, Train Loss: 0.10407031449293895\n",
      "For Epoch: 4, Step: 1200, Train Loss: 0.10386324289575108\n",
      "For Epoch: 4, Step: 1300, Train Loss: 0.10378252705995804\n",
      "For Epoch: 4, Step: 1400, Train Loss: 0.10391298673786409\n",
      "For Epoch: 4, Step: 1500, Train Loss: 0.10364745960116069\n",
      "For Epoch: 4, Step: 1600, Train Loss: 0.10379953965135175\n",
      "For Epoch: 4, Step: 1700, Train Loss: 0.10385431905333467\n",
      "For Epoch: 4, Step: 1800, Train Loss: 0.10398691197829336\n",
      "For Epoch: 4, Step: 1900, Train Loss: 0.103849086934002\n",
      "For Epoch: 4, Step: 2000, Train Loss: 0.10379361911401756\n",
      "For Epoch: 4, Step: 2100, Train Loss: 0.1038552930065276\n",
      "For Epoch: 4, Step: 2200, Train Loss: 0.10383157502827672\n",
      "For Epoch: 4, Step: 2300, Train Loss: 0.1038371505801028\n",
      "For Epoch: 4, Train Loss: 0.1038943714430374, Train Accuracy: 0.8271990300478463\n",
      "Validation Loop\n",
      "For Epoch: 4, Step: 0, Val Loss: 0.0979515090584755\n",
      "For Epoch: 4, Step: 100, Val Loss: 0.09856087839839482\n",
      "For Epoch: 4, Step: 200, Val Loss: 0.1006606497537734\n",
      "For Epoch: 4, Step: 300, Val Loss: 0.10136691182604264\n",
      "For Epoch: 4, Step: 400, Val Loss: 0.1027771970930688\n",
      "For Epoch: 4, Step: 500, Val Loss: 0.10341462663964121\n",
      "For Epoch: 4, Val Loss: 0.10408236089475559, Val Accuracy: 0.8271120878158308\n",
      "Epoch: 5\n",
      "Training Loop\n",
      "For Epoch: 5, Step: 0, Train Loss: 0.06330765038728714\n",
      "For Epoch: 5, Step: 100, Train Loss: 0.10164520697723521\n",
      "For Epoch: 5, Step: 200, Train Loss: 0.10342164515559353\n",
      "For Epoch: 5, Step: 300, Train Loss: 0.10376149703101858\n",
      "For Epoch: 5, Step: 400, Train Loss: 0.10314027098311748\n",
      "For Epoch: 5, Step: 500, Train Loss: 0.10339495881707844\n",
      "For Epoch: 5, Step: 600, Train Loss: 0.10292367454302093\n",
      "For Epoch: 5, Step: 700, Train Loss: 0.10334123200743582\n",
      "For Epoch: 5, Step: 800, Train Loss: 0.1035483761059211\n",
      "For Epoch: 5, Step: 900, Train Loss: 0.10325490818519174\n",
      "For Epoch: 5, Step: 1000, Train Loss: 0.10343946024894596\n",
      "For Epoch: 5, Step: 1100, Train Loss: 0.10329312291148574\n",
      "For Epoch: 5, Step: 1200, Train Loss: 0.10346983845883066\n",
      "For Epoch: 5, Step: 1300, Train Loss: 0.10346198696743333\n",
      "For Epoch: 5, Step: 1400, Train Loss: 0.10343875841029536\n",
      "For Epoch: 5, Step: 1500, Train Loss: 0.10322620314381506\n",
      "For Epoch: 5, Step: 1600, Train Loss: 0.10336244678698354\n",
      "For Epoch: 5, Step: 1700, Train Loss: 0.10343212294427877\n",
      "For Epoch: 5, Step: 1800, Train Loss: 0.10332768745947916\n",
      "For Epoch: 5, Step: 1900, Train Loss: 0.10340500671391045\n",
      "For Epoch: 5, Step: 2000, Train Loss: 0.1033911769506873\n",
      "For Epoch: 5, Step: 2100, Train Loss: 0.10354123855349225\n",
      "For Epoch: 5, Step: 2200, Train Loss: 0.10364723891723919\n",
      "For Epoch: 5, Step: 2300, Train Loss: 0.10369335793635473\n",
      "For Epoch: 5, Train Loss: 0.1036494057827487, Train Accuracy: 0.8275438376665193\n",
      "Validation Loop\n",
      "For Epoch: 5, Step: 0, Val Loss: 0.0971812903881073\n",
      "For Epoch: 5, Step: 100, Val Loss: 0.09870392659513078\n",
      "For Epoch: 5, Step: 200, Val Loss: 0.10074513231343891\n",
      "For Epoch: 5, Step: 300, Val Loss: 0.10137141039254657\n",
      "For Epoch: 5, Step: 400, Val Loss: 0.10270200328822444\n",
      "For Epoch: 5, Step: 500, Val Loss: 0.10331897830177923\n",
      "For Epoch: 5, Val Loss: 0.10396341036840515, Val Accuracy: 0.8271120878158308\n",
      "Epoch: 6\n",
      "Training Loop\n",
      "For Epoch: 6, Step: 0, Train Loss: 0.12386219948530197\n",
      "For Epoch: 6, Step: 100, Train Loss: 0.10472798247886177\n",
      "For Epoch: 6, Step: 200, Train Loss: 0.10369610328653558\n",
      "For Epoch: 6, Step: 300, Train Loss: 0.10307076924861072\n",
      "For Epoch: 6, Step: 400, Train Loss: 0.10335833637828838\n",
      "For Epoch: 6, Step: 500, Train Loss: 0.10249133614038755\n",
      "For Epoch: 6, Step: 600, Train Loss: 0.10332031097393266\n",
      "For Epoch: 6, Step: 700, Train Loss: 0.10345604045903802\n",
      "For Epoch: 6, Step: 800, Train Loss: 0.10367680377746641\n",
      "For Epoch: 6, Step: 900, Train Loss: 0.103666487365928\n",
      "For Epoch: 6, Step: 1000, Train Loss: 0.10324932813837931\n",
      "For Epoch: 6, Step: 1100, Train Loss: 0.10355788427358535\n",
      "For Epoch: 6, Step: 1200, Train Loss: 0.10366375419271677\n",
      "For Epoch: 6, Step: 1300, Train Loss: 0.10374716775267057\n",
      "For Epoch: 6, Step: 1400, Train Loss: 0.10384381369160466\n",
      "For Epoch: 6, Step: 1500, Train Loss: 0.10364526233013513\n",
      "For Epoch: 6, Step: 1600, Train Loss: 0.10361025045898689\n",
      "For Epoch: 6, Step: 1700, Train Loss: 0.1036395382821595\n",
      "For Epoch: 6, Step: 1800, Train Loss: 0.10356587822911542\n",
      "For Epoch: 6, Step: 1900, Train Loss: 0.10354808481240636\n",
      "For Epoch: 6, Step: 2000, Train Loss: 0.1035007026766998\n",
      "For Epoch: 6, Step: 2100, Train Loss: 0.1034665068506003\n",
      "For Epoch: 6, Step: 2200, Train Loss: 0.10347836468197821\n",
      "For Epoch: 6, Step: 2300, Train Loss: 0.10361941734483479\n",
      "For Epoch: 6, Train Loss: 0.10356136380979873, Train Accuracy: 0.8274381755278183\n",
      "Validation Loop\n",
      "For Epoch: 6, Step: 0, Val Loss: 0.09748160094022751\n",
      "For Epoch: 6, Step: 100, Val Loss: 0.09853756058924269\n",
      "For Epoch: 6, Step: 200, Val Loss: 0.10057975121991551\n",
      "For Epoch: 6, Step: 300, Val Loss: 0.10125522898429652\n",
      "For Epoch: 6, Step: 400, Val Loss: 0.10261551696723537\n",
      "For Epoch: 6, Step: 500, Val Loss: 0.10323458739710663\n",
      "For Epoch: 6, Val Loss: 0.10388142417330261, Val Accuracy: 0.8271120878158308\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    clear_gpu_memory()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(\"Training Loop\")\n",
    "    training_loop(\n",
    "        epoch, model, optimizer, scheduler, train_dataloader, device, label_key_map\n",
    "    )\n",
    "    print(\"Validation Loop\")\n",
    "    val_labels, val_preds = validation_loop(\n",
    "        epoch, model, test_dataloader, device, label_key_map, key_label_map\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-283527.4375, device='cuda:0')\n",
      "tensor(2.8671, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().get(\"bert.bert.embeddings.word_embeddings.weight\").sum())\n",
    "print(model.state_dict().get(\"bert.bert.embeddings.position_embeddings.weight\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"On 11 March 1990 , Lithuania became the first of the Soviet republics to declare its independence , but Moscow did not recognize this proclamation until September of 1991 ( following the abortive coup in Moscow ) .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_word_ids_test(texts, tokenizer, label_all_tokens):\n",
    "\n",
    "    tokenized_inputs = tokenizer.encode_plus(\n",
    "        texts,\n",
    "        max_length=MAX_LEN,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    sub_word_tokens = tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"][0])\n",
    "    sub_word_tokens = [\n",
    "        i for i in sub_word_tokens if i not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]\n",
    "    ]\n",
    "    # print(len([id for id in word_ids if id != None]))\n",
    "    # print(f\"Word ids: {word_ids}\")\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(1)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(1 if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return tokenized_inputs, label_ids, sub_word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs, test_label_ids, sub_word_tokens = align_word_ids_test(\n",
    "    test_text, bert_tokenizer, label_all_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tokenized_inputs['attention_mask'].to(device)\n",
    "input_id = tokenized_inputs['input_ids'].to(device)\n",
    "label_ids = torch.Tensor(test_label_ids).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128]) torch.Size([1, 128]) torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "print(input_id.shape, mask.shape, label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits,  = model(input_id, mask, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten targets and predictions\n",
    "flattened_targets = label_ids.view(\n",
    "    -1\n",
    ")  # from (batch_size, seq_len) to (batch_size*seq_len,)\n",
    "len([id for id in flattened_targets if id != -100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 17]), torch.Size([1, 128, 17]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "active_logits = logits.view(\n",
    "    -1, len(label_key_map)\n",
    ")  # from (batch_size, seq_len, num_labels) to (batch_size*seq_len, num_labels)\n",
    "\n",
    "active_logits.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "flattened_predictions = torch.argmax(\n",
    "    active_logits, axis=1\n",
    ")  # from (batch_size*seq_len, num_labels) to (batch_size*seq_len,)\n",
    "\n",
    "flattened_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41])\n"
     ]
    }
   ],
   "source": [
    "# only consider labels and predictions to store and calc metric on valid ones\n",
    "active_accuracy = label_ids.view(-1) != -100\n",
    "# print(active_accuracy)\n",
    "\n",
    "labels = torch.masked_select(\n",
    "    flattened_targets, active_accuracy\n",
    ")  # shape (valid_labels,)\n",
    "\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_predictions = torch.masked_select(\n",
    "    flattened_predictions, active_accuracy\n",
    ")  # shape (valid_labels,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "prediction_label = [key_label_map[i] for i in active_predictions.tolist()]\n",
    "print(prediction_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_label),len(sub_word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is problematic , ignore this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
